<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>CSE 5522: Survey of Artificial Intelligence II: Advanced Techniques</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- Le styles -->
    <link href="../bootstrap-3.2.0-dist/css/bootstrap.css" rel="stylesheet">
    <style>
      body {
        padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
      }
    </style>
    <link href="../bootstrap-3.2.0-dist/css/bootstrap-responsive.css" rel="stylesheet">

    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <!-- Le fav and touch icons -->
    <link rel="shortcut icon" href="../bootstrap-3.2.0-dist/ico/favicon.ico">
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="../bootstrap-3.2.0-dist/ico/apple-touch-icon-144-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="114x114" href="../bootstrap-3.2.0-dist/ico/apple-touch-icon-114-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="72x72" href="../bootstrap-3.2.0-dist/ico/apple-touch-icon-72-precomposed.png">
    <link rel="apple-touch-icon-precomposed" href="../bootstrap-3.2.0-dist/ico/apple-touch-icon-57-precomposed.png">
  </head>

  <body>

    <div class="container">

<div id="Content">
    <h1>CSE 5522: Survey of Artificial Intelligence II: Advanced Techniques</h1>


<p>
This course provides an overview of modern statistical AI, including probability and statistics, graphical models, and machine learning. The course also includes applications to computer vision, natural language processing, information retrieval, and speech processing.
</p>
    </div>

<div class="panel panel-default">
  <!-- Default panel contents -->
  <div class="panel-heading">Details</div>

<ul class="list-group">
<li class="list-group-item">Instructor: Alan Ritter (ritter.1492@osu.edu)</li>
<li class="list-group-item">Time: Tuesday, Thursday 11:10 - 12:30</li>
<li class="list-group-item">Place: Dreese Lab 305</li>
<li class="list-group-item">Office Hours: Wednesdays 3:00-4:00pm, Dreese 595</li>
</ul>
</div>

<div class="panel panel-default">
<div class="panel-heading">Topics:</div>
<ul class="list-group">
<li class="list-group-item">Background in probability and statistics</li>
<li class="list-group-item">Basics of Bayesian and Markov Networks</li>
<li class="list-group-item">Inference in Graphical Models</li>
<li class="list-group-item">Linear Regression</li>
<li class="list-group-item">Classification Algorithms</li>
<li class="list-group-item">Clustering</li>
<li class="list-group-item">Computer Vision Applications</li>
<li class="list-group-item">Information Retrieval and NLP applications</li>
<li class="list-group-item">Speech Applications</li>
<li class="list-group-item">Other topics, time permitting</li>
</li>
</div>

<div class="panel panel-default">
<div class="panel-heading">Textbook:</div>
  <div class="panel-body">
    There is no official textbook, however, the following books are relevant to the material.
    The Russell and Norvig book is the one traditionally used for the class.  
  </div>
<ul class="list-group">
<li class="list-group-item">Stuart Russell and Peter Norvig.  <i>Artificial Intelligence: A Modern Approach (3rd Edition)</i>, Prentice Hall, 2009.
<li class="list-group-item">Daphne Koller and Nir Friedman.  <i>Probabilistic Graphical Models: Principles and Techniques</i>, MIT Press, 2009.
<li class="list-group-item">Murphy, Kevin P. <i>Machine learning: a probabilistic perspective</i>, MIT press, 2012.
<li class="list-group-item">Christopher M. Bishop.  <i>Pattern Recognition and Machine Learning</i>, Springer, 2006.
</li>
</div>

<div class="panel panel-default">
  <!-- Default panel contents -->
  <div class="panel-heading">Grading</div>

  <div class="panel-body">
    <p>
      Grading will be based on:

      <h4>Homeworks (30%)</h4>

      The homeworks will include both written and programming assignments.  For programming asignments, include a README, and make sure your code is easy to run following the instructions.
      Homework should be submitted to a Dropbox folder which will be set up in <a href='https://carmen.osu.edu/'>Carmen</a> by 11:59pm on the day it is due.  Late homework will be accepted
      up to 48 hours later for 50% credit.  After 48 hours, late homework will not be accepted.
      Please email your homework to the instructor if there are any technical issues with submission.

      <h4>midterm + final (40%)</h4>
      The midterm will be in class on March 5th.  The final is scheduled for Monday May 4 from 10am - 11:45.  Each will be worth 20% of the grade, for a total of 40%.

      <h4>Projects (30%)</h4>
      The project is an open-ended assignment, where the goal is for you to get some experience applying the techniques we learn about in class to real-world datasets.  
      Students will work in groups of 2-4.  Examples projects can be found <a href='http://cs229.stanford.edu/projects2011.html'>Here</a>.  
      It is a good idea to run your proposed project by the instructor to get feedback before beginning experiments.  The final project report should be 4 pages and
      is due on May 30.  The final report should describe the problem you are solving, what data is being used, the proposed techique you are applying in addition to
      what is a reasonable baseline to compare against.  You can use any software for the project, including off-the-shelf machine learning toolkits, for example
      <a href='http://scikit-learn.org/stable/'>Scikit-Learn</a>, or if you prefer you can implement one of the algorithms we have disucssed in class.

    </p>
  </div>
</div>

<div class="panel panel-default">
  <!-- Default panel contents -->
  <div class="panel-heading">Homeworks</div>

  <div class="panel-body">
    <list>
    <li><a href='hw/hw1.pdf'>Homework 1</a> (Due Feb. 5) Data: <a href='hw/wine.train'>wine.train</a>, <a href='hw/wine.test'>wine.test</a>, <a href='hw/wine-true.data'>wine.true</a> for more details on the data see: <a href='https://archive.ics.uci.edu/ml/datasets/Wine'>UCI Wine Data</a></li>
    <li><a href='hw/hw2.pdf'>Homework 2</a> (Due March 3 before class)</li>
    </list>
  </div>
</div>

<div class="panel panel-default">
  <!-- Default panel contents -->
  <div class="panel-heading">Schedule</div>

  <!-- Table -->
  <table class="table">
      <thead>
	<tr>
	  <th>Date</th>
	  <th>Topic</th>
	  <th>Reading</th>
	</tr>
      </thead>
    <tr>
      <td>1/13</td>
      <td><a href='slides/introduction.pptx'>Course Overview</a></td>
      <td>No Reading</td>
    </tr>
    <tr>
      <td>1/15</td>
      <td><a href='slides/probability_basics.pptx'>Probability Theory Review</a></td>
      <td>(R+N Ch 13, K+F Ch 2)</td>
    </tr>
    <tr>
      <td>1/20</td>
      <td><a href='slides/statistical_estimation.pptx'>Statistical Estimation</a></td>
      <td>(K+F Ch 17, R+N Ch 20, <a href='http://www.arbylon.net/publications/text-est2.pdf'>Notes on Parameter Estimation (Sections 1-3 are relevant)</a>)</td>
    </tr>
    <tr>
      <td>1/22</td>
      <td><a href='slides/mixture_models_em.pptx'>Mixture Models and the EM Algorithm</a></td>
      <td>(R+N Chapter 20, Murphy Ch 11, K+F Chapter 19)</td>
    </tr>
    <tr>
      <td>1/27</td>
      <td><a href='slides/hmms.pptx'>Hidden Markov Models</a> (<a href='slides/hmms.pdf'>PDF</a>)</td>
      <td>(R+N Chapter 15, Murphy Ch 17, <a href='rabiner.pdf'>Notes on HMMs</a>)</td>
    </tr>
    <tr>
      <td>1/29</td>
      <td>No Class (AAAI)</td>
      <td></td>
    </tr>
    <tr>
      <td>2/10</td>
      <td><a href='slides/bayesian_networks.pptx'>Bayesian Networks</a> (<a href='slides/bayesian_networks.pdf'>PDF</a>)</td>
      <td>(R+N Chapter 14, Murphy Chapter 10, K+F Chapter 3)</td>
    </tr>
    <tr>
      <td>2/12</td>
      <td><a href='slides/markov_networks.pptx'>Markov Networks</a> (<a href='slides/markov_networks.pdf'>PDF</a>)</td>
      <td>(Murphy Chapter 19, K+F Chapter 4)</td>
    </tr>
    <tr>
      <td>2/16</td>
      <td><a href='slides/exact_inference.pptx'>Exact Inference</a> (<a href='slides/exact_inference.pdf'>PDF</a>)</td>
      <td>(Murphy Chapter 20, R+N Chapter 14 <!--, <a href='http://www.comm.utoronto.ca/~frank/papers/KFL01.pdf'>Notes on the Sum-Product Algorithm</a>) --></td>
    </tr>
    <tr>
      <td>2/16</td>
      <td><a href='slides/jtbp.ppt'>Junction Trees</a> (<a href='slides/jtbp.pdf'>PDF</a>)</td>
      <td>(Murphy Chapter 20, R+N Chapter 14 <!--, <a href='http://www.comm.utoronto.ca/~frank/papers/KFL01.pdf'>Notes on the Sum-Product Algorithm</a>) --></td>
    </tr>
    <tr>
      <td>3/3</td>
      <td><a href='slides/midterm review.pptx'>Midterm Review</a></td>
      <td></td>
    </tr>
    <tr>
      <td>3/10</td>
      <td><a href='slides/sampling.pdf>Sampling-Based Inference</a></td>
      <td>R+N Chapter 14, K+F Chapter 11</td>
    </tr>
    <tr>
      <td>3/12</td>
      <td><a href='slides/learnbn.ppt>Learning Bayesian Networks</a></td>
      <td>Murphy Chapter 10+26, K+F Chapters 17+18</td>
    </tr>
  </table>
</div>


</div> <!-- End Content -->


    <script src="../bootstrap-3.2.0-dist/js/bootstrap-min.js"></script>

  </body>
</html>
